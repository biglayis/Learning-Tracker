{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "acb873b0",
   "metadata": {},
   "source": [
    "# 赛事背景\n",
    "近年来人工智能在自然语言处理领域取得了巨大的进展。其中一项引人注目的技术是生成模型，如OpenAI的GPT-3.5。这类模型通过学习大量的文本数据，具备了生成高质量文本的能力，从而引发了一系列关于文本生成真实性的讨论。 \n",
    "\n",
    "正因为生成模型的迅猛发展，也引发了一个新的挑战，即如何区分人类编写的文本与机器生成的文本。传统上，我们借助语法错误、逻辑不连贯等特征来辨别机器生成的文本，但随着生成模型的不断改进，这些特征变得越来越难以区分。因此，为了解决这一问题，研究人员开始探索使用NLP文本分类技术来区分人类编写的文本和机器生成的文本。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12c5c28f",
   "metadata": {},
   "source": [
    "# 数据说明\n",
    "数据集为中文作文样本，其中从互联网上采集得到了真实作文，并且ChatGLM-6B生成了部分作文。参赛选手的任务是根据文本内容，区分作文的来源。  \n",
    "\n",
    "本次竞赛的评价标准采用准确率 accuracy_score 指标，最高分为1。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f439834d",
   "metadata": {},
   "source": [
    "# 任务一：报名比赛，下载比赛数据集并完成读取\n",
    "<img src=\"img/报名.png\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6e288338",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>label</th>\n",
       "      <th>content</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>[4509 3181 1253 2278  290 3562 2051  599 3125 ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>[ 263 1325 2563 4160 2196  169 3125 2563 2619 ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>[3635  177 3125 1251 3839 5212 2109 1171 1194 ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>[3037  266  246 3547 1253 2278 3125  649  697 ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>[ 177 3125 1547 4060 5212 4687 5164 3125 3974 ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   name  label                                            content\n",
       "0     1      0  [4509 3181 1253 2278  290 3562 2051  599 3125 ...\n",
       "1     2      1  [ 263 1325 2563 4160 2196  169 3125 2563 2619 ...\n",
       "2     3      0  [3635  177 3125 1251 3839 5212 2109 1171 1194 ...\n",
       "3     4      1  [3037  266  246 3547 1253 2278 3125  649  697 ...\n",
       "4     5      0  [ 177 3125 1547 4060 5212 4687 5164 3125 3974 ..."
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "train_data = pd.read_csv(\"data/train.csv\")\n",
    "test_data = pd.read_csv(\"data/test.csv\")\n",
    "train_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e75ef80",
   "metadata": {},
   "source": [
    "数据集包含三列：name、label和content。  \n",
    "\n",
    "* name：数据的索引或编号。\n",
    "* label：文本的标签，表示文本原始是否来自ChatGPT/ChatGLM。0表示人类编写的文本，1表示机器生成的文本。\n",
    "* content：文本经过匿名编码后的结果，按照字符进行编码。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a0f4b2a",
   "metadata": {},
   "source": [
    "# 任务二：对数据集字符进行可视化，统计标签和字符分布"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "96c86cbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 对输入的内容进行处理\n",
    "train_data['content'] = train_data['content'].apply(lambda x: x[1:-1].strip().replace('\\n', ' \\n '))\n",
    "test_data['content'] = test_data['content'].apply(lambda x: x[1:-1].strip().replace('\\n', ' \\n '))\n",
    "\n",
    "train_data['content'] = train_data['content'].apply(lambda x: x.split())\n",
    "test_data['content'] = test_data['content'].apply(lambda x: x.split())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "62df7b14",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('5212', 173863),\n",
       " ('3125', 116815),\n",
       " ('1759', 72557),\n",
       " ('123', 69893),\n",
       " ('0', 61434),\n",
       " ('139', 58299),\n",
       " ('205', 43617),\n",
       " ('2113', 35667),\n",
       " ('998', 28072),\n",
       " ('148', 24948)]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 统计字符出现的频次并输出前10个最常见的字符\n",
    "from collections import Counter\n",
    "\n",
    "c = Counter()\n",
    "for content in train_data['content']:\n",
    "    c.update(content)\n",
    "c.most_common(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a5ff50fc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 对数据集的字符进行可视化展示。\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "counts = pd.DataFrame(c.most_common(10),columns=[\"word\",\"num\"])\n",
    "counts = counts.sort_values(by=\"num\",ascending=False)\n",
    "counts.plot.bar(x=\"word\",y=\"num\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ae8c38b",
   "metadata": {},
   "source": [
    "# 任务三：使用TFIDF提取文本特征"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5109cec",
   "metadata": {},
   "source": [
    "## TF-IDF模型介绍"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cad12c0c",
   "metadata": {},
   "source": [
    "TF-IDF是一种统计方法，用以评估某一字词对于一个文件集或一个语料库的重要程度。字词的重要性随着它在文件中出现的次数成正比增加，但同时会随着它在语料库中出现的频率成反比下降。  \n",
    "\n",
    "TF-IDF的主要思想是，如果某个词或短语在一篇文章中出现的频率TF(Term Frequency，词频)，词频高，并且在其他文章中很少出现，则认为此词或者短语具有很好的类别区分能力，适合用来分类。  \n",
    "\n",
    "TF（Term Frequency）指的是词频，表示一个词在文档中出现的频率。IDF（inverse document frequency，逆向文件频率）是文档集合中的文档总数除以包含该词的文档数的对数。计算公式为：$IDF = \\log(\\frac{N}{DF + 1})$。其中，N表示文档集合中的文档总数，DF表示包含某个词的文档数。公式中的 \"+1\" 是为了避免分母为零的情况。取对数用于平滑计算结果，并且能够将IDF值映射到一个更合适的范围内，以便更好地与其他特征进行比较和组合。  \n",
    "\n",
    "当一个词在更多的文档中出现时，它的IDF值趋近于0，表示这个词在文档集合中的重要性较低。相反，当一个词在较少的文档中出现时，它的IDF值较高，表示这个词在文档集合中的重要性较高。 \n",
    "\n",
    "TF-IDF实际上是：$TF \\times IDF$。得分越高表示词在文档中越重要。  \n",
    "\n",
    "TF-IDF模型仅考虑了词频和逆文档频率，没有考虑词的顺序和语义信息。因此，在某些情况下，它可能无法捕捉到文本的完整语义信息。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f49d4b8",
   "metadata": {},
   "source": [
    "## 提取文本特征"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "554a774f",
   "metadata": {},
   "source": [
    "TfidfVectorizer是scikit-learn库中的一个文本特征提取工具，用于将文本数据转换为TF-IDF特征表示。下面是对TfidfVectorizer函数的功能和常用超参数的介绍：  \n",
    "\n",
    "* ngram_range：可以指定要考虑的词组的长度范围，如(1, 1)表示只考虑单个词，(1, 2)表示同时考虑单个词和相邻的词对。\n",
    "* max_features：可以限制提取的特征数量，只保留最重要的特征。\n",
    "* max_df：单词的最大文档频率，超过该频率的单词将被忽略，默认为1.0，表示不忽略任何单词。\n",
    "* min_df：单词的最小文档频率，低于该频率的单词将被忽略，默认为1，表示不忽略任何单词。\n",
    "* stop_words：可以指定一个停用词列表，用于过滤掉常见的无意义词语，如\"a\"、\"the\"等。\n",
    "* vocabulary：可以指定自定义的词汇表，用于控制所考虑的词语。\n",
    "* sublinear_tf：子线性TF缩放。通过将sublinear_tf设置为True，可以使用子线性缩放来平衡长文本和短文本的特征权重，从而提高模型对不同长度文本的适应性。\n",
    "* norm：特征向量的归一化方式。通过调整norm参数，可以选择不同的归一化方式，如'l2'、'l1'或'none'，以适应不同的数据分布。\n",
    "* smooth_idf：控制IDF平滑的方式，设置为True表示使用平滑，避免除零错误。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "77f77126",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "tfidf = TfidfVectorizer()\n",
    "train_tfidf_feat = tfidf.fit_transform(train_data['content'].apply(lambda x: ' '.join(x)))\n",
    "test_tfidf_feat = tfidf.transform(test_data['content'].apply(lambda x: ' '.join(x)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0bb6b05b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.         0.05019706 0.         ... 0.         0.07660908 0.        ]\n",
      " [0.         0.         0.         ... 0.         0.05343725 0.        ]\n",
      " [0.         0.02602664 0.         ... 0.         0.039721   0.        ]\n",
      " ...\n",
      " [0.         0.         0.         ... 0.         0.01761612 0.        ]\n",
      " [0.         0.05004152 0.         ... 0.         0.07637172 0.        ]\n",
      " [0.         0.02263174 0.         ... 0.         0.05180972 0.        ]]\n"
     ]
    }
   ],
   "source": [
    "print(train_tfidf_feat.toarray())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7e438be0",
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf = TfidfVectorizer(ngram_range=(1,2), max_features=10000)\n",
    "train_tfidf_feat = tfidf.fit_transform(train_data['content'].apply(lambda x: ' '.join(x)))\n",
    "test_tfidf_feat = tfidf.transform(test_data['content'].apply(lambda x: ' '.join(x)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e5235bf5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.03910991 0.07374304 0.         ... 0.         0.         0.        ]\n",
      " [0.         0.         0.         ... 0.         0.         0.        ]\n",
      " [0.01894004 0.         0.         ... 0.         0.         0.        ]\n",
      " ...\n",
      " [0.         0.         0.         ... 0.         0.         0.        ]\n",
      " [0.03226617 0.         0.         ... 0.         0.         0.        ]\n",
      " [0.0148205  0.         0.         ... 0.         0.         0.        ]]\n"
     ]
    }
   ],
   "source": [
    "print(train_tfidf_feat.toarray())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64880647",
   "metadata": {},
   "source": [
    "# 任务四：使用TFIDF特征和线性模型完成训练和预测"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "746c0805",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.981     1.000     0.990      9479\n",
      "           1      0.999     0.895     0.944      1721\n",
      "\n",
      "    accuracy                          0.984     11200\n",
      "   macro avg      0.990     0.947     0.967     11200\n",
      "weighted avg      0.984     0.984     0.983     11200\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_val_predict,train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "# 划分训练集和验证集\n",
    "X_train, X_val, y_train, y_val = train_test_split(train_tfidf_feat, train_data['label'], test_size=0.2, random_state=42)\n",
    "\n",
    "# 逻辑回归模型\n",
    "lr = LogisticRegression()\n",
    "\n",
    "# 使用cross_val_predict()函数进行交叉验证\n",
    "val_pred = cross_val_predict(\n",
    "    lr,\n",
    "    X_train,\n",
    "    y_train,\n",
    "    cv=5\n",
    ")\n",
    "\n",
    "# 模型在训练集上的性能\n",
    "print(classification_report(y_train, val_pred, digits=3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "62d167bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.978     1.000     0.989      2357\n",
      "           1      1.000     0.883     0.938       443\n",
      "\n",
      "    accuracy                          0.981      2800\n",
      "   macro avg      0.989     0.941     0.963      2800\n",
      "weighted avg      0.982     0.981     0.981      2800\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 训练模型\n",
    "lr.fit(X_train,y_train)\n",
    "y_pred_val = lr.predict(X_val)\n",
    "\n",
    "# 模型在验证集上的性能\n",
    "print(classification_report(y_val, y_pred_val,digits=3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9daea953",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 生成测试集结果\n",
    "lr.fit(train_tfidf_feat, train_data['label'])\n",
    "test_pred = lr.predict(test_tfidf_feat)\n",
    "test_data['label'] = test_pred\n",
    "test_data[['name', 'label']].to_csv('data/lr.csv', index=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "767a4e17",
   "metadata": {},
   "source": [
    "<img src=\"img/lr.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd3a595b",
   "metadata": {},
   "source": [
    "# 任务五：使用TFIDF特征和XGBoost完成训练和预测"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "73da8c44",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.990     0.997     0.993      9479\n",
      "           1      0.981     0.944     0.962      1721\n",
      "\n",
      "    accuracy                          0.989     11200\n",
      "   macro avg      0.986     0.970     0.978     11200\n",
      "weighted avg      0.989     0.989     0.988     11200\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from xgboost import XGBClassifier\n",
    "\n",
    "tfidf = TfidfVectorizer(ngram_range=(1,3), max_features=10000)\n",
    "tfidf.fit(train_data['content'].apply(lambda x: ' '.join(x)))\n",
    "train_tfidf_feat = tfidf.transform(train_data['content'].apply(lambda x: ' '.join(x)))\n",
    "test_tfidf_feat = tfidf.transform(test_data['content'].apply(lambda x: ' '.join(x)))\n",
    "\n",
    "# 划分训练集和验证集\n",
    "X_train, X_val, y_train, y_val = train_test_split(train_tfidf_feat, train_data['label'], test_size=0.2, random_state=42)\n",
    "\n",
    "# 创建模型\n",
    "xgb = XGBClassifier(n_estimators=50)\n",
    "\n",
    "# 交叉验证\n",
    "val_pred = cross_val_predict(\n",
    "    xgb,\n",
    "    X_train,\n",
    "    y_train,\n",
    "    cv = 5\n",
    ")\n",
    "\n",
    "# 模型在训练集上的性能\n",
    "print(classification_report(y_train, val_pred, digits=3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2c73b151",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.841     0.995     0.912      2357\n",
      "           1      0.077     0.002     0.004       443\n",
      "\n",
      "    accuracy                          0.838      2800\n",
      "   macro avg      0.459     0.499     0.458      2800\n",
      "weighted avg      0.720     0.838     0.768      2800\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 训练模型\n",
    "xgb.fit(X_train,y_train)\n",
    "y_pred_val = lr.predict(X_val)\n",
    "\n",
    "# 模型在验证集上的性能\n",
    "print(classification_report(y_val, y_pred_val,digits=3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d9562af5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 生成测试集结果\n",
    "xgb.fit(train_tfidf_feat, train_data['label'])\n",
    "test_pred = xgb.predict(test_tfidf_feat)\n",
    "test_data['label'] = test_pred\n",
    "test_data[['name', 'label']].to_csv('data/xgb.csv', index=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4d480c5",
   "metadata": {},
   "source": [
    "<img src=\"img/xgb.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64252b6b",
   "metadata": {},
   "source": [
    "# 任务六：学会训练Word2Vec词向量"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "721320ef",
   "metadata": {},
   "source": [
    "## Word2Vec词向量模型介绍"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3202ddc",
   "metadata": {},
   "source": [
    "Word2Vec是一种用于将文本中的单词表示为向量的机器学习模型。它包含两个模型，连续词袋（Continuous Bag of Words，简称CBOW）和跳字模型（Skip-gram）。这两种方法都是基于神经网络的训练模型。CBOW模型可以根据上下文单词来预测当前单词，跳字模型可以根据当前单词来预测上下文单词。  \n",
    "\n",
    "word2vec将字词转换成向量形式，可以把对文本内容的处理简化为向量空间中的向量运算，计算出向量空间上的相似度，来表示文本语义上的相似度。它计算的是余弦值，距离范围为0–1之间，值越大代表两个词越相似。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3173638-33d7-4d8f-8c10-205d7f736e7f",
   "metadata": {},
   "source": [
    "## 使用Word2Vec类"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72d8e568-9c1d-42a7-9773-f12b4a68f4c1",
   "metadata": {},
   "source": [
    "**Word2Vec()**\n",
    "* sentences: 输入的训练数据，可以是一个可迭代对象，每个元素是一个句子的单词列表。也可以通过corpus_file参数指定从文件中读取训练数据。\n",
    "* vector_size: 生成的词向量的维度，默认为100。\n",
    "* alpha: 学习率（初始学习率），用于控制训练过程中的学习速度，默认为0.025。\n",
    "* window: 上下文窗口大小，表示当前单词与目标单词之间的最大距离，默认为5。\n",
    "* min_count: 单词的最低频次阈值，低于该频次的单词将被忽略，默认为5。\n",
    "* sg: 选择训练算法，0表示CBOW，1表示Skip-gram，默认为0。\n",
    "* hs: 选择层次softmax训练算法，0表示负采样，1表示层次softmax，默认为0。\n",
    "* negative: 如果使用负采样，指定生成负样本的数量，默认为5。\n",
    "* workers：一个用于训练并行化的参数，可以加快训练速度，默认为3.\n",
    "* epochs: 训练迭代次数，默认为5。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "6fdcb795",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Word2Vec<vocab=4914, vector_size=100, alpha=0.025>\n"
     ]
    }
   ],
   "source": [
    "from gensim.models import Word2Vec\n",
    "\n",
    "# 创建Word2Vec模型\n",
    "model = Word2Vec(sentences=list(train_data['content']), vector_size=100, window=5, min_count=1, workers=4)\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "bb191aea-0373-458d-92b2-28ec16a3842b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.43731368, -0.01557103, -1.1169655 ,  0.38070336, -0.866342  ,\n",
       "        1.1366763 ,  1.6273082 , -0.30970496,  0.15261187, -0.28252137,\n",
       "       -1.899728  ,  0.74838614, -0.23713487, -0.45594892, -0.5663476 ,\n",
       "        0.21906477,  0.39660767,  1.7780344 ,  0.6653069 ,  0.04034795,\n",
       "        0.29974264, -2.662975  ,  0.8533107 ,  1.7924706 , -0.7434167 ,\n",
       "       -1.4550394 ,  0.1037167 , -1.2934539 , -1.5472313 ,  0.01657655,\n",
       "        1.1610568 , -1.7037338 ,  0.3350013 , -0.9269314 ,  1.9165641 ,\n",
       "       -1.5024201 ,  0.10790921,  0.2993678 , -1.4763    ,  1.5369719 ,\n",
       "        1.0640609 , -0.560476  , -1.1750845 ,  0.8878865 ,  0.86859906,\n",
       "       -1.276011  ,  1.1003003 ,  0.4173871 , -0.6910702 , -1.1921325 ,\n",
       "       -1.5250986 ,  0.02588342,  0.83173174, -0.04457463,  0.41301095,\n",
       "       -1.5562114 , -2.0595477 , -0.7391433 ,  0.8313659 , -0.98364526,\n",
       "        0.1720823 , -0.399128  ,  0.7176993 ,  0.6142262 , -1.6582322 ,\n",
       "       -0.42309308,  0.38311931, -0.63009644, -1.0117877 ,  0.360814  ,\n",
       "       -0.0110259 , -1.3457825 , -0.6701588 ,  1.1564829 ,  0.47320348,\n",
       "        1.4888961 , -0.34149313,  1.6198758 ,  1.1483155 , -0.13464087,\n",
       "       -0.02732961, -1.6297281 ,  1.3240663 , -0.49141118, -0.57334876,\n",
       "       -0.9223068 , -0.43949804,  0.3484479 , -1.910846  , -0.08734416,\n",
       "        0.03652934, -1.6378286 ,  0.5226033 ,  0.02161969, -1.099175  ,\n",
       "        0.3787113 , -0.31927246,  1.7239941 ,  0.8200569 ,  0.8778858 ],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 获取单词的向量表示\n",
    "model.wv['0']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "24c29fa1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('14', 0.9448967576026917),\n",
       " ('67', 0.8672031760215759),\n",
       " ('82', 0.8661262392997742),\n",
       " ('81', 0.8648353815078735),\n",
       " ('87', 0.8641952872276306),\n",
       " ('63', 0.8625372052192688),\n",
       " ('77', 0.861719012260437),\n",
       " ('75', 0.8561267256736755),\n",
       " ('70', 0.8434911370277405),\n",
       " ('80', 0.8260563015937805)]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 查找与给定单词最相似的单词\n",
    "model.wv.most_similar('1', topn=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "14d073a1-799e-45ee-979e-3b05e2259448",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.30987188"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 计算两个单词之间的相似度\n",
    "model.wv.similarity('0', '1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "56b1507c-f306-4d07-829f-25b13a6ed4c0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4914, 100)"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 词向量矩阵的维度\n",
    "model.wv.vectors.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "c5b1568c-f642-456b-835a-2791409b3d39",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'14'"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 找出这些词中与其他词汇差异最大的词\n",
    "model.wv.doesnt_match(['14','67','1','70','77','75','80','81'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06b39d41",
   "metadata": {},
   "source": [
    "# 任务七：使用Word2Vec词向量，搭建TextCNN模型进行训练和预测"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a6dbc22-0b09-41c2-ae82-30e3b7f973ee",
   "metadata": {},
   "source": [
    "## 使用Word2Vec获得训练数据"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e71daa2-98f6-429f-bd82-09b66727e393",
   "metadata": {},
   "source": [
    "**build_vocab()**\n",
    "* sentences：输入的训练数据，可以是一个可迭代对象，每个元素是一个句子的单词列表。\n",
    "* update：是否更新已有的词汇表，默认为False。如果设置为True，则会在现有的词汇表基础上更新新的词汇。\n",
    "* progress_per：用于显示进度的参数，表示多少个句子显示一次进度。默认为10000。\n",
    "* keep_raw_vocab：是否保留原始词汇表，默认为False。如果设置为True，则在构建新的词汇表时保留原始词汇的信息。\n",
    "* trim_rule：用于修剪词汇表的规则。如果指定了修剪规则函数，则会在构建词汇表后应用该函数进行修剪。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ecc946a5-2c70-4dae-80a2-952f8b2def1f",
   "metadata": {},
   "source": [
    "**train()**\n",
    "* sentences: 输入的训练数据，与构造函数中的sentences参数相同。\n",
    "* total_examples: 训练样本的总数，用于学习率调整，默认为None，如果提供了该参数，则不需要提供epochs参数。\n",
    "* epochs: 训练迭代次数，用于学习率调整，默认为None，如果提供了该参数，则不需要提供total_examples参数。\n",
    "* start_alpha: 初始学习率，如果没有指定，则使用构造函数中的alpha参数。\n",
    "* end_alpha: 最终学习率，如果没有指定，则使用构造函数中的min_alpha参数。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "5125f3be-249e-48de-88f4-688a3d1c9e6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences=list(train_data['content'])\n",
    "# 创建Word2Vec模型\n",
    "model = Word2Vec(vector_size=100, window=8, min_count=1, workers=4, epochs=20)\n",
    "# 构建词汇表\n",
    "model.build_vocab(sentences)\n",
    "# 训练模型\n",
    "model.train(sentences, total_examples=model.corpus_count,epochs=model.epochs,end_alpha=0.01)\n",
    "# 得到训练数据\n",
    "train_data_wv = model.wv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "3fa2a2e4-10f7-4c59-bfbc-247f6a190264",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.80623174,  0.12166563, -0.99643224, ..., -0.2187935 ,\n",
       "         0.669113  , -0.19976653],\n",
       "       [-0.7008419 ,  0.6971608 ,  0.6098954 , ...,  0.2660851 ,\n",
       "        -0.22692603, -0.41258377],\n",
       "       [ 0.96653616, -0.95108795, -1.193532  , ..., -0.12667349,\n",
       "         0.47273108, -0.31615722],\n",
       "       ...,\n",
       "       [-0.09011073, -0.1225181 ,  0.00354682, ..., -0.01854029,\n",
       "        -0.03406965, -0.29819834],\n",
       "       [-0.05112632,  0.04503568,  0.04370062, ...,  0.03290649,\n",
       "        -0.01098526, -0.30140993],\n",
       "       [ 0.01712559,  0.04288544, -0.16115916, ..., -0.04906145,\n",
       "         0.01299014, -0.15191647]], dtype=float32)"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data_wv.vectors"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "baff97cf-901e-4f01-a771-997fbbf55699",
   "metadata": {},
   "source": [
    "## TextCNN模型介绍"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa4c45be-d9d9-4f13-8882-b00c163157db",
   "metadata": {},
   "source": [
    "TextCNN（Text Convolutional Neural Network）是一种用于文本分类的卷积神经网络模型。它的核心思想是通过卷积操作和池化操作来捕捉文本中的局部特征，从而对文本进行分类。TextCNN模型的基本结构和运行过程：\n",
    "* 输入层：将文本表示为一个矩阵，每一行表示一个词或字符的词向量。\n",
    "* 卷积层：TextCNN模型通常使用多个不同大小的卷积核对输入矩阵进行卷积操作。每个卷积核的目的是捕捉不同大小的局部特征。例如，对于英文文本，一个卷积核可能关注一对相邻的词语，而另一个卷积核可能关注更大范围的词语。通过卷积操作，可以得到一系列特征图（feature maps）。\n",
    "* 池化层：对于每个特征图，使用最大池化（Max pooling）操作或平均池化（Average pooling）操作来降低维度。池化操作能够提取特征图中最显著的特征，并保留最重要的信息。\n",
    "* 全连接层：将池化层的输出连接到一个或多个全连接层，用于学习文本的高级表示和进行分类任务。通常还会使用激活函数（如ReLU）来引入非线性。\n",
    "* 输出层：最后一层是一个softmax层，将全连接层的输出映射到不同类别的概率分布。模型通过训练数据进行优化，使得在给定文本输入时，能够预测正确的分类标签。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "fdba67c8-6c84-45ec-b3c0-48536258f88f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 下面是让chatgpt写的\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "\n",
    "# 构建词向量矩阵\n",
    "embedding_matrix = np.zeros((len(train_data_wv) + 1, train_data_wv.vector_size))\n",
    "for i, word in enumerate(train_data_wv.index_to_key):\n",
    "    embedding_vector = train_data_wv[word]\n",
    "    embedding_matrix[i + 1] = embedding_vector\n",
    "    \n",
    "# 将文本转换为词索引序列\n",
    "max_seq_length = max(len(sentence) for sentence in sentences)\n",
    "indexed_sentences = []\n",
    "for sentence in sentences:\n",
    "    indexed_sentence = [train_data_wv.key_to_index[word] + 1 for word in sentence]\n",
    "    indexed_sentence += [0] * (max_seq_length - len(sentence))  # 使用0填充到相同长度\n",
    "    indexed_sentences.append(indexed_sentence)\n",
    "\n",
    "# 转换为PyTorch的Tensor类型\n",
    "x_train = torch.tensor(indexed_sentences, dtype=torch.long)\n",
    "y_train = torch.tensor(train_data['label'], dtype=torch.float)\n",
    "\n",
    "# 构建数据集和数据加载器\n",
    "dataset = TensorDataset(x_train, y_train)\n",
    "dataloader = DataLoader(dataset, batch_size=2, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b47e9082-92f9-449b-8207-c7180be90905",
   "metadata": {},
   "source": [
    "## 构建TextCNN模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "385a35fd-9582-4cfd-b8ec-57942d062464",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 定义TextCNN模型\n",
    "class TextCNN(nn.Module):\n",
    "    def __init__(self, embedding_matrix, num_filters, filter_sizes, num_classes):\n",
    "        super(TextCNN, self).__init__()\n",
    "\n",
    "        self.embedding = nn.Embedding.from_pretrained(torch.FloatTensor(embedding_matrix), freeze=True)\n",
    "        self.convs = nn.ModuleList([\n",
    "            nn.Conv2d(1, num_filters, (fs, embedding_matrix.shape[1])) for fs in filter_sizes\n",
    "        ])\n",
    "        self.dropout = nn.Dropout(0.5)\n",
    "        self.fc = nn.Linear(len(filter_sizes) * num_filters, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.embedding(x)\n",
    "        x = x.unsqueeze(1)\n",
    "        x = [nn.functional.relu(conv(x)).squeeze(3) for conv in self.convs]\n",
    "        x = [nn.functional.max_pool1d(conv, conv.size(2)).squeeze(2) for conv in x]\n",
    "        x = torch.cat(x, 1)\n",
    "        x = self.dropout(x)\n",
    "        x = self.fc(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2614336-9175-4197-8f1a-54b800978071",
   "metadata": {},
   "source": [
    "## 将Word2Vec词向量应用到模型中"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "ab7144ef-8943-40cd-b1f1-29dcc0da792a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/20], Loss: 0.0\n",
      "Epoch [2/20], Loss: 2.807300006679725e-05\n",
      "Epoch [3/20], Loss: 1.4900939277140424e-05\n",
      "Epoch [4/20], Loss: 0.0\n",
      "Epoch [5/20], Loss: 0.0\n",
      "Epoch [6/20], Loss: 0.0\n",
      "Epoch [7/20], Loss: 0.0\n",
      "Epoch [8/20], Loss: 0.0\n",
      "Epoch [9/20], Loss: 0.0\n",
      "Epoch [10/20], Loss: 0.0\n",
      "Epoch [11/20], Loss: 0.0\n",
      "Epoch [12/20], Loss: 0.0\n",
      "Epoch [13/20], Loss: 0.0\n",
      "Epoch [14/20], Loss: 0.0\n",
      "Epoch [15/20], Loss: 0.0\n",
      "Epoch [16/20], Loss: 0.0\n",
      "Epoch [17/20], Loss: 0.0\n",
      "Epoch [18/20], Loss: 0.0\n",
      "Epoch [19/20], Loss: 0.0\n",
      "Epoch [20/20], Loss: 0.0\n"
     ]
    }
   ],
   "source": [
    "# 初始化模型\n",
    "vocab_size = len(word_vectors) + 1\n",
    "embedding_dim = 100\n",
    "num_filters = 128\n",
    "filter_sizes = [2, 3, 4]\n",
    "num_classes = 1\n",
    "text_cnn_model = TextCNN(embedding_matrix, num_filters, filter_sizes, num_classes)\n",
    "\n",
    "# 定义损失函数和优化器\n",
    "criterion = nn.BCEWithLogitsLoss()\n",
    "optimizer = optim.Adam(text_cnn_model.parameters(), lr=0.001)\n",
    "\n",
    "# 模型训练\n",
    "num_epochs = 20\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "text_cnn_model.to(device)\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    for inputs, labels in dataloader:\n",
    "        inputs = inputs.to(device)\n",
    "        labels = labels.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        outputs = text_cnn_model(inputs)\n",
    "        loss = criterion(outputs.squeeze(), labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    print(f\"Epoch [{epoch+1}/{num_epochs}], Loss: {loss.item()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "b45800f6-6025-493c-9345-ce70a4b998d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 模型预测\n",
    "test_sentences=list(test_data['content'])\n",
    "indexed_test_sentences = []\n",
    "for text in test_sentences:\n",
    "    indexed_test_sentence = [train_data_wv.key_to_index[word] + 1 for word in text if word in train_data_wv]\n",
    "    indexed_test_sentence += [0] * (max_seq_length - len(indexed_test_sentence))\n",
    "    indexed_test_sentences.append(indexed_test_sentence)\n",
    "\n",
    "x_test = torch.tensor(indexed_test_sentences, dtype=torch.long).to(device)\n",
    "predictions = torch.sigmoid(text_cnn_model(x_test)).squeeze().tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "d7c244a3-6d4c-4b24-af4b-0da32f39ddb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data['label'] = [1 if pred > 0.5 else 0 for pred in predictions]\n",
    "test_data[['name', 'label']].to_csv('data/textcnn.csv', index=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "349f95fe-8371-4f6d-a2a3-4ee3cf58d608",
   "metadata": {},
   "source": [
    "<img src=\"img/textcnn.png\">>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d1a45f1",
   "metadata": {},
   "source": [
    "# 任务八：使用Word2Vec词向量，搭建BILSTM模型进行训练和预测"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0016744f-101e-48aa-98d4-99917feb5043",
   "metadata": {},
   "source": [
    "## BILSTM模型介绍\n",
    "BILSTM（Bidirectional Long Short-Term Memory）是一种用于序列建模的深度学习模型，它结合了双向递归神经网络（RNN）和长短期记忆（LSTM）的思想，利用LSTM单元处理输入序列的时序信息，并且通过引入双向上下文来更好地理解和建模序列。\n",
    "\n",
    "BILSTM模型的基本结构由两个LSTM组成，一个按原始顺序处理输入序列，另一个按相反顺序处理输入序列。这种设计允许模型同时从过去和未来的上下文中学习特征。两个方向的LSTM计算结果会被连接起来，形成最终的表示。这样，BILSTM模型可以更好地捕捉到序列中的长期依赖关系和上下文信息。\n",
    "\n",
    "BILSTM模型的输入是一个序列，例如一个句子或一个时间序列，每个元素都表示序列中的一个时间步。每个时间步的输入都被嵌入到一个向量空间中，以便于模型处理。在经过输入层后，BILSTM模型的主要组成部分是两个LSTM层，分别处理正向和反向的上下文。每个LSTM层包含多个LSTM单元，这些单元通过一个门控机制来控制信息的流动和记忆的更新。\n",
    "\n",
    "BILSTM模型的输出可以是各种形式，根据任务的不同而定。例如，在序列标注任务中，输出可以是每个时间步的标签；在文本分类任务中，输出可以是整个序列的分类结果。\n",
    "\n",
    "BILSTM模型在许多NLP任务中表现出色，它能够学习到上下文相关的特征，有效地处理长距离依赖关系，对于处理序列数据具有很强的表达能力。然而，BILSTM模型也存在一些限制，例如它对序列长度的处理有限制，较长的序列可能导致内存消耗过大或模型性能下降。此外，BILSTM模型对于捕捉更大范围的上下文信息有一定的限制，因为它仅考虑了局部的前后上下文。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "4d0f270c-8678-43c7-bd00-63742ea5d84d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 定义BILSTM模型\n",
    "class BILSTM(nn.Module):\n",
    "    def __init__(self, embedding_matrix, hidden_dim, num_layers, num_classes):\n",
    "        super(BILSTM, self).__init__()\n",
    "\n",
    "        self.embedding = nn.Embedding.from_pretrained(torch.FloatTensor(embedding_matrix), freeze=True)\n",
    "        self.bilstm = nn.LSTM(embedding_matrix.shape[1], hidden_dim, num_layers, batch_first=True, bidirectional=True)\n",
    "        self.fc = nn.Linear(hidden_dim * 2, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.embedding(x)\n",
    "        _, (h_n, _) = self.bilstm(x)\n",
    "        h_n = torch.cat((h_n[-2, :, :], h_n[-1, :, :]), dim=1)\n",
    "        x = self.fc(h_n)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "badeb0dd-ae78-4e94-bb1d-3172f0f11631",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 初始化模型\n",
    "hidden_dim = 128\n",
    "num_layers = 1\n",
    "num_classes = 1\n",
    "bilstm_model = BILSTM(embedding_matrix, hidden_dim, num_layers, num_classes)\n",
    "\n",
    "# 定义损失函数和优化器\n",
    "criterion = nn.BCEWithLogitsLoss()\n",
    "optimizer = optim.Adam(bilstm_model.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "1e4a5636-465c-4011-967f-2cbb21a0f498",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/20], Loss: 0.009044078178703785\n",
      "Epoch [2/20], Loss: 0.0004037315375171602\n",
      "Epoch [3/20], Loss: 0.002809701254591346\n",
      "Epoch [4/20], Loss: 0.0032373229041695595\n",
      "Epoch [5/20], Loss: 0.0002015027275774628\n",
      "Epoch [6/20], Loss: 1.1920927533992653e-07\n",
      "Epoch [7/20], Loss: 5.793270975118503e-05\n",
      "Epoch [8/20], Loss: 4.768370445162873e-07\n",
      "Epoch [9/20], Loss: 2.682201738934964e-06\n",
      "Epoch [10/20], Loss: 8.344643447344424e-07\n",
      "Epoch [11/20], Loss: 1.7225447663804516e-05\n",
      "Epoch [12/20], Loss: 7.563468534499407e-05\n",
      "Epoch [13/20], Loss: 3.483414888381958\n",
      "Epoch [14/20], Loss: 0.0\n",
      "Epoch [15/20], Loss: 0.0\n",
      "Epoch [16/20], Loss: 0.00011991029168711975\n",
      "Epoch [17/20], Loss: 3.5762775496550603e-07\n",
      "Epoch [18/20], Loss: 5.9604641222676946e-08\n",
      "Epoch [19/20], Loss: 0.0\n",
      "Epoch [20/20], Loss: 0.0\n"
     ]
    }
   ],
   "source": [
    "# 模型训练\n",
    "num_epochs = 20\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "bilstm_model.to(device)\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    for inputs, labels in dataloader:\n",
    "        inputs = inputs.to(device)\n",
    "        labels = labels.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        outputs = bilstm_model(inputs)\n",
    "        loss = criterion(outputs.squeeze(), labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    print(f\"Epoch [{epoch+1}/{num_epochs}], Loss: {loss.item()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "584320a8-cec2-4714-933c-ccb24c88a4ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 模型预测\n",
    "predictions = torch.sigmoid(bilstm_model(x_test)).squeeze().tolist()\n",
    "test_data['label'] = [1 if pred > 0.5 else 0 for pred in predictions]\n",
    "test_data[['name', 'label']].to_csv('data/bilstm.csv', index=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2d852ef-d75a-4e55-99ff-9c09c5c43327",
   "metadata": {},
   "source": [
    "<img src=\"img/bilstm.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b201795d",
   "metadata": {},
   "source": [
    "# 任务九：学会Bert基础，transformer库基础使用"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e2325c0-e11b-41f7-99e2-451ed1e7de5f",
   "metadata": {},
   "source": [
    "Transformer "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "809bac24-f3de-4a59-a4ca-579cdadcc4bb",
   "metadata": {},
   "source": [
    "## Bert模型介绍\n",
    "BERT（Bidirectional Encoder Representations from Transformers）是由Google于2018年提出的一种预训练模型，它是基于Transformer模型的一种改进和扩展。BERT是一种双向（bidirectional）的自然语言处理模型，通过在大规模无标签文本上进行预训练，学习到了丰富的语言表示。\n",
    "\n",
    "传统的自然语言处理模型通常采用单向的语言模型，即从左到右或从右到左进行建模，而BERT则采用了双向的机制。这使得BERT能够更好地理解上下文和语境，并在各种自然语言处理任务中表现出色。\n",
    "\n",
    "BERT的训练过程包括两个阶段：预训练和微调。在预训练阶段，BERT使用大量无标签的文本数据进行训练，通过预测输入文本中的遮蔽词（masked words）和句子关系任务来学习词汇和句子级别的表示。在微调阶段，BERT通过在特定任务上进行少量的有标签数据的训练来适应具体的任务，如文本分类、命名实体识别、句子关系判断等。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d20639b-fc7f-4711-9413-04d7b09430cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import BertTokenizer, BertModel, AutoModel\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb979bb1",
   "metadata": {},
   "source": [
    "# 任务十：使用Bert在比赛数据集中完成预训练"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9bc9a919",
   "metadata": {},
   "source": [
    "# 任务十一：使用Bert在比赛数据集上完成微调"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0bc6bdb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
